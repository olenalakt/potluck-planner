server.port: 7443

# DB config
spring.data.mongodb.uri: mongodb://localhost/guestdb

# reporting metrics to prometheus
management:
  endpoints:
    enabled-by-default: true
    web.exposure.include: prometheus,info,health
  endpoint:
    prometheus.enabled: true

guest-service:
  cors-config:
    contentSecurityPolicy: "default-src blob: localhost:*, *.lakt.ca"
    accessControlAllowCredentials: true
    accessControlAllowOriginList:
      - "http://localhost[:]*"
      - "https://localhost[:]*"
      - "http://*[.]lakt[.]ca"
      - "https://*[.]lakt[.]ca"
  config:
    appVersion: 1.0.0
    dbSchemaVersion: 1.0.0
    dishServiceUrl: http://localhost:6443/v1/dishes
    drinkServiceUrl: http://localhost:5443/v1/drinks

# mTLS related
#server.ssl.key-store: guestservice.jks
#server.ssl.key-store-password: olena123
#server.ssl.keyAlias: guestservice

# can not use curl to  guest service when uncommented
#server.ssl.client-auth:  need

# openid oath-server config
security:
  oauth2:
    resource.token-info-uri: http://localhost:8080/oauth/check_token
    client:
      clientId: potluckPlanner
      clientSecret: potluckPlannerSecret

# JWT related
#security.oauth2.resource.user-info-uri: https://localhost:8443/user
#security.oauth2.resource.jwt.keyUri: https://localhost:8443/oauth/token_key

logging:
  config: classpath:logback-spring.xml
  level:
    com.olena.guestservice: debug
    org.springframework.security: debug
    org.springframework.web: debug
    org.springframework.data.mongodb: error
    org.mongodb.driver: error
    org.springframework.kafka: error
    root: error

confluent-kafka:
  config:
    # topic
    potluckEventProducerTopic: 'POTLUCK-EVENT-DEV'
    keySerializerClass: 'org.apache.kafka.common.serialization.StringSerializer'
    valueSerializerCLass: 'com.olena.guestservice.model.GuestMessageSerializer'

    # shared prop
    bootstrapServers: 'localhost:9092'

    # producer clientId
    clientId: 'potluck-event-dev'

    # consumer group
    groupId: 'potluck-event-dev'

    #consumer prop
    fetchMinBytes: 4
    fetchMaxBytes: 52428800
    fetchMaxWaitMs: 500
    receiveBufferBytes: 65536
    maxPartitionFetchBytes: 1048576

    connectionsMaxIdleMs: 540000
    sessionTimeoutMs: 10000
    heartbeatIntervalMs: 3000
    requestTimeoutMs: 30000

    autoOffsetReset: earliest
    # consumer was failing to  start in Dev with "resolve_canonical_bootstrap_servers_only"
    clientDnsLookup: resolve_canonical_bootstrap_servers_only

    enableAutoCommit: true
    autoCommitIntervalMs: 5000

    reconnectBackoffMs: 500
    retryBackoffMs: 500
    reconnectBackoffMaxMs: 1000

    # profile specific consumer props
    maxPollRecords: 500
    pollFrequencyMs: 500

    # producer props
    schemaRegistryUrlConfig: TBD

    # depends on profile
    acks: all
    lingerMs: 10

    bufferMemory: 33554432
    batchSize: 16384
    deliveryTimeoutMs: 120000
    maxBlockMs: 60000
    maxRequestSize: 1048576
    enableIdempotence: false
    maxInFlightRequestsPerConnection: 5
    metadataMaxAgeMs: 300000

    #shared props
    #    securityProtocol: SASL_SSL
    #    sslAlgorithm: https
    #    sslTruststoreLocation: 'kafka_devtest_truststore.pkcs12'
    #    sslTruststorePassword: server-keystore
    #    saslMechanism: SCRAM-SHA-256
    # setup this value via ENV variable SASL_JAAS_CONFIG_CRED
#    saslJaasConfig: 'org.apache.kafka.common.security.scram.ScramLoginModule required ${SASL_JAAS_CONFIG_CRED};'